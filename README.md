# Number Recognition with ML

## Learning Notes

### Lexicon

#### Basic concepts

Perceptrons neuron = Computing Neuron | 0 or 1

sigmoid neuron σ = similar to perceptrons, but modified so that small changes in their weights and bias cause only a small change in their output | 0 to 1

logistic neurons ~= sigmoid neuron | use sigmoid function as its activation function

weights = use to place importance on each input

bias = use to place importance on the neuron

partial derivative ∂ = how changing one variable of the function affect the output, keeping other constant

activation function = function that will generate the output of the neuron (sigmoid)

#### Architectural concepts

input layer

hidden layers

output layers

multilayer perceptrons or MLPs = neural network with input, hidden and output layers

feedforward neural network = direction of the flow of information between its layers is always in one direction

recurrent neural networks = some neuron will fire back in feedback depending on time

### Ressources

[Chapter 1 | NN&DL](http://neuralnetworksanddeeplearning.com/chap1.html)
